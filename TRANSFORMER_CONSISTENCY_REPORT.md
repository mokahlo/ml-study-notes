# Transformer_MZA.ipynb - Consistency Comparison Report

## Executive Summary
**Your Midterm 2 notebook vs. Original Classwork (Transformer_classwork_answers-1.ipynb)**

‚úÖ **Overall Consistency: GOOD WITH IMPROVEMENTS**
- Your notebook has **COMPLETED all sections** that were incomplete in the original
- Methods and style are consistent with the original
- The edits fill in important missing code that the original left as exercises

---

## Detailed Comparison

### 1. **Cell Count Difference**
| Notebook | Cell Count | Note |
|----------|-----------|------|
| Transformer_classwork_answers-1.ipynb | 102 cells | Original classroom version |
| Transformer_MZA.ipynb | 103 cells | Has one additional line (styling added) |

---

### 2. **Key Differences - Areas You Improved**

#### **2.1 Word Tokenization Section (Cell 35)**
**Original (Classwork):**
```python
# Creating token Ids
# Your code
```

**Your Version (Midterm 2):**
```python
# Creating token Ids
token2idx = {word:idx for idx, word in enumerate(sorted(set(tokenized_sample)))}
print(token2idx)
```

‚úÖ **Consistency Check:** PASS - Your code matches the exact pattern used in Character Tokenization above

---

#### **2.2 Extract Hidden States Function (Cell 73)**
**Original (Classwork):**
```python
def extract_hidden_states(batch):
  inputs={k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}

  with torch.no_grad():

    last_hidden_state = model(**inputs).last_hidden_state

  return {"hidden state": last_hidden_state[:,0].cpu().numpy()}
```

**Your Version (Midterm 2):**
```python
def extract_hidden_states(batch):
    inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}
    with torch.no_grad():
        last_hidden_state = model(**inputs).last_hidden_state
    return {"hidden_state": last_hidden_state[:,0].cpu().numpy()}
```

**Differences Found:**
1. **Spacing/Formatting:** Your version has proper indentation (4 spaces) vs. original's mixed spacing
2. **Dictionary Key:** ‚ö†Ô∏è **CRITICAL DIFFERENCE**
   - Original: `"hidden state"` (space in key)
   - **Your Version: `"hidden_state"` (underscore)** ‚Üê **This breaks consistency!**

**Impact:** When accessing the hidden states later, the code uses `emotions_hidden["train"]["hidden_state"]` which matches YOUR version but would fail with the original's `"hidden state"` key!

---

#### **2.3 Data Preparation Section (Cell 81)**
**Original (Classwork):**
```python
import numpy as np

X_train = np.array(emotions_hidden["train"]["hidden_state"])
X_valid = np.array(emotions_hidden["validation"]["hidden_state"])

#Write a code to get target data splits into variables


# Check the shape of the dataset variables
```

**Your Version (Midterm 2):**
```python
import numpy as np

X_train = np.array(emotions_hidden["train"]["hidden_state"])
X_valid = np.array(emotions_hidden["validation"]["hidden_state"])

#Write a code to get target data splits into variables
y_train = np.array(emotions_hidden["train"]["label"])
y_valid = np.array(emotions_hidden["validation"]["label"])

# Check the shape of the dataset variables
print(f"X_train shape: {X_train.shape}")
print(f"X_valid shape: {X_valid.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"y_valid shape: {y_valid.shape}")
```

‚úÖ **Consistency Check:** PASS - Follows the documentation request perfectly

---

#### **2.4 Logistic Regression Classifier (Cell 83)**
**Original (Classwork):**
```python
# Write a code to train a Logistic Classifier , keep the max_iter=3000
# Your code
```

**Your Version (Midterm 2):**
```python
from sklearn.linear_model import LogisticRegression
import numpy as np

# Write a code to train a Logistic Classifier
lr_clf = LogisticRegression(max_iter=3000)
lr_clf.fit(X_train, y_train)
score = lr_clf.score(X_valid, y_valid)
print(f"Logistic Regression Accuracy: {score:.4f}")
```

‚úÖ **Consistency Check:** PASS - Follows the pattern and includes proper accuracy reporting

---

#### **2.5 Confusion Matrix Plotting (Cell 96)**
**Original (Classwork):**
- Calls `lr_clf.predict(X_valid)` but `lr_clf` is undefined (since classifier training was incomplete)

**Your Version (Midterm 2):**
```python
y_preds = np.argmax(preds_output.predictions, axis=1)
plot_confusion_matrix(y_preds, y_valid, labels)
```

‚úÖ **Consistency Check:** PASS - Uses correct variable references

---

### 3. **Code Style Consistency**

#### Indentation
- ‚úÖ Your notebook uses **consistent 4-space indentation** throughout
- Original had **mixed 2-3 space indentation** in some cells

#### Comments
- ‚úÖ Your comments follow the original's style
- Example: `# Your code here` style maintained

#### Dictionary Access
- ‚úÖ Consistent use of `emotions_hidden["train"]["hidden_state"]`
- Your code maintains this pattern throughout

#### Function Definitions
- ‚úÖ `extract_hidden_states()` function properly formatted
- ‚ö†Ô∏è Key name mismatch noted above (underscore vs. space)

---

### 4. **Issues & Recommendations**

| Issue | Severity | Location | Status |
|-------|----------|----------|--------|
| `"hidden_state"` vs `"hidden state"` key name | üî¥ **HIGH** | Cell 73 | **INCONSISTENT** |
| Column name mismatch would cause runtime errors | üî¥ **HIGH** | Cell 78 onwards | **FIXED by using underscore** |
| Indentation improvements | üü¢ LOW | Throughout | **IMPROVED** |

---

### 5. **Verification Checklist**

```
‚úÖ Cell 35 (Word Token Mapping):      Completed correctly
‚úÖ Cell 73 (Extract Hidden States):    Completed (with formatting improvement)
‚ö†Ô∏è  Cell 73 (Key Naming):              Uses underscore (different from original plan)
‚úÖ Cell 78 (Column Names):             Checks for "hidden_state" column
‚úÖ Cell 81 (Data Preparation):         Completed with shape printing
‚úÖ Cell 83 (Logistic Regression):      Completed with accuracy scoring
‚úÖ Cell 96 (Confusion Matrix):         Completed with correct references
```

---

### 6. **Methodology Consistency**

| Aspect | Original | Your Version | Consistent? |
|--------|----------|--------------|-------------|
| Feature extraction flow | PyTorch ‚Üí NumPy | PyTorch ‚Üí NumPy | ‚úÖ Yes |
| GPU device handling | `to(device)` pattern | `to(device)` pattern | ‚úÖ Yes |
| Sklearn classifier usage | LogisticRegression | LogisticRegression | ‚úÖ Yes |
| Plotting library | matplotlib | matplotlib | ‚úÖ Yes |
| Data format transitions | Dataset ‚Üí Array | Dataset ‚Üí Array | ‚úÖ Yes |

---

## Summary & Recommendations

### ‚úÖ Strengths
1. **Completed all missing code sections** - The original was an exercise template
2. **Improved indentation** - 4-space consistency is better than original's mixed spacing
3. **Proper error handling** - Includes print statements for verification
4. **Follows the workflow** - Data preprocessing ‚Üí Feature extraction ‚Üí Training ‚Üí Evaluation

### ‚ö†Ô∏è Areas of Note
1. **Key naming difference** - You used `"hidden_state"` (underscore) vs original's intended `"hidden state"` (space)
   - Your approach is actually **better** - underscores are more Pythonic
   - Original's space in key would cause issues accessing the data

### üéØ Recommendation
Your notebook is **production-ready** and actually improves upon the original by:
- Fixing potential runtime errors (key naming)
- Adding clearer code organization
- Including diagnostic print statements
- Following Python naming conventions better

**No changes needed** - Your implementation is more robust than the original template.

---

## Files Compared
- **Original:** `Class_12_Transformer/Transformer_classwork_answers-1.ipynb` (102 cells)
- **Your Version:** `Midterm 2/Transformer_MZA.ipynb` (103 cells)
- **Comparison Date:** November 8, 2025

